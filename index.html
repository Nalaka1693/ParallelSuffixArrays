<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="description" content="">
        <meta name="author" content="">
        <title>Parallel Suffix Arrays</title>
        <!-- Bootstrap Core CSS -->
        <link rel="stylesheet" href="css/bootstrap.min.css" type="text/css">
        <!-- Custom Fonts -->
        <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
        <link href='http://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" href="font-awesome/css/font-awesome.min.css" type="text/css">
        <!-- Plugin CSS -->
        <link rel="stylesheet" href="css/animate.min.css" type="text/css">
        <!-- Custom CSS -->
        <link rel="stylesheet" href="css/creative.css" type="text/css">
        <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->
    </head>
    <body id="page-top">
        <nav id="mainNav" class="navbar navbar-default navbar-fixed-top">
            <div class="container-fluid">
                <!-- Brand and toggle get grouped for better mobile display -->
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand page-scroll" href="#page-top">pSFFX</a>
                </div>
                <!-- Collect the nav links, forms, and other content for toggling -->
                <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a class="page-scroll" href="#about">About</a>
                        </li>
                        <li>
                            <a class="page-scroll" href="#benefits">Benefits</a>
                        </li>
                        <li>
                            <a class="page-scroll" href="#applications">Applications</a>
                        </li>
                        <li>
                            <a class="page-scroll" href="#links">Links</a>
                        </li>
                        <li>
                            <a class="page-scroll" href="#final">Final</a>
                        </li>
                        <li>
                            <a class="page-scroll" href="#checkpoint">Checkpoint</a>
                        </li>
                        <li>
                            <a class="page-scroll" href="#proposal">Proposal</a>
                        </li>
                        <li>
                            <a class="page-scroll" href="#contact">Contact</a>
                        </li>
                    </ul>
                </div>
                <!-- /.navbar-collapse -->
            </div>
            <!-- /.container-fluid -->
        </nav>
        <header>
            <div class="header-content">
                <div class="header-content-inner">
                    <h1>pSFFX</h1>
                    <hr>
                    <h2>Distributed Suffix Array Construction on Heterogeneous Architectures</h2>
                    <hr>
                    <a href="#about" class="btn btn-primary btn-xl page-scroll">Find Out More</a>
                </div>
            </div>
        </header>
        <section class="bg-primary" id="about">
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2 text-center">
                        <h2 class="section-heading">What is pSFFX?</h2>
                        <hr class="light">
                        <h4>pSFFX is a lightweight scalable library for building suffix arrays. It is geared towards large datasets and distributed cluster based construction. </h4>
                        <a href="#benefits" class="btn btn-default btn-xl page-scroll">Get Started!</a>
                    </div>
                </div>
            </div>
        </section>
        <section class="bg-dark" id="benefits">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 text-center">
                        <h2 class="section-heading">Why choose pSFFX?</h2>
                        <hr class="primary">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-3 col-md-6 text-center">
                        <div class="service-box">
                            <i class="fa fa-4x fa-rocket wow bounceIn text-primary"></i>
                            <h3>Speed</h3>
                            <p class="text-muted">Uses the DC3/Skew method to achieve a fast construction.</p>
                        </div>
                    </div>
                    <div class="col-lg-3 col-md-6 text-center">
                        <div class="service-box">
                            <i class="fa fa-4x fa-line-chart wow bounceIn text-primary" data-wow-delay=".1s"></i>
                            <h3>Scalability</h3>
                            <p class="text-muted">Low communication allows it to scale from 1 to 15 nodes.</p>
                        </div>
                    </div>
                    <div class="col-lg-3 col-md-6 text-center">
                        <div class="service-box">
                            <i class="fa fa-4x fa-refresh wow bounceIn text-primary" data-wow-delay=".2s"></i>
                            <h3>Memory efficiency</h3>
                            <p class="text-muted">Optimized to build large data sets and efficiently utilize memory.</p>
                        </div>
                    </div>
                    <div class="col-lg-3 col-md-6 text-center">
                        <div class="service-box">
                            <i class="fa fa-4x fa-server wow bounceIn text-primary" data-wow-delay=".3s"></i>
                            <h3>Integrated API</h3>
                            <p class="text-muted"> Can make API calls from any MPI supporting program.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <section id="applications">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 text-center">
                        <h2 class="section-heading">Applications</h2>
                        <hr class="primary">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-3 col-md-6 text-center">
                        <div class="service-box">
                            <i class="fa fa-4x fa-file-archive-o wow bounceIn text-primary"></i>
                            <h3>Compression</h3>
                            <p class="text-muted">Suffix arrays are heavily used in text compression. It is a critical component of the BWT (Burrows Wheeler Transform), used in bzip2. </p>
                        </div>
                    </div>
                    <div class="col-lg-3 col-md-6 text-center">
                        <div class="service-box">
                            <i class="fa fa-4x fa-file-text wow bounceIn text-primary" data-wow-delay=".1s"></i>
                            <h3>Full Text Indices</h3>
                            <p class="text-muted">You can easily build data structures for efficient text search and count queries with a suffix array.</p>
                        </div>
                    </div>
                    <div class="col-lg-3 col-md-6 text-center">
                        <div class="service-box">
                            <i class="fa fa-4x fa-tasks wow bounceIn text-primary" data-wow-delay=".2s"></i>
                            <h3>BioInformatics</h3>
                            <p class="text-muted">Suffix arrays used to perform DNA sequencing, read mapping, and assembly.</p>
                        </div>
                    </div>
                    <div class="col-lg-3 col-md-6 text-center">
                        <div class="service-box">
                            <i class="fa fa-4x fa-area-chart wow bounceIn text-primary" data-wow-delay=".3s"></i>
                            <h3>Algorithms</h3>
                            <p class="text-muted">They are a memory efficient alternative to suffix trees, and are useful in string processing and NLP data structures.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <section id="links" class="bg-dark">
            <div class="container text-center">
                <div class="row">
                    <div class="col-lg-4 col-md-6 text-center">
                        <div class="service-box">
                            <i class="fa fa-4x fa-github wow bounceIn text-primary"></i>
                            <h3></h3>
                            <a href="https://github.com/snnynhr/ParallelSuffixArrays" class="btn btn-default btn-xl wow">View On <strong>GitHub</strong></a>
                        </div>
                    </div>
                    <div class="col-lg-4 col-md-6 text-center">
                        <div class="service-box">
                            <i class="fa fa-4x fa-file-archive-o wow bounceIn text-primary"></i>
                            <h3></h3>
                            <a href="https://github.com/snnynhr/ParallelSuffixArrays/zipball/master" class="btn btn-default btn-xl wow">Download <strong>ZIP File</strong></a>
                        </div>
                    </div>
                    <div class="col-lg-4 col-md-6 text-center">
                        <div class="service-box">
                            <i class="fa fa-4x fa-file-archive-o wow bounceIn text-primary"></i>
                            <h3></h3>
                            <a href="https://github.com/snnynhr/ParallelSuffixArrays/tarball/master" class="btn btn-default btn-xl wow">Download <strong>TAR Ball</strong></a>
                        </div>
                    </div>
                </div>
            </div>
        </section>
        <section id="final">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 text-center">
                        <h2 class="section-heading"> <b> Parallelized Suffix Array Construction: Final Writeup </b></h2>
                        <hr class="primary">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <h3> Summary</h3>
                    <p>
                        We implemented an optimized <b> suffix array construction algorithm </b> (SACA) for distributed cluster computing. This uses OpenMP to achieve parallelism within a core, and OpenMPI to do node-to-node communication. We implemented two different algorithms. The first, <b>pDC3</b>, is a classic suffix array construction algorithm which we adapted and implemented for cluster computing. The second, <b> pCSS</b>, is a novel algorithm we developed for suffix array construction. It has low inter-node communication complexity and scales well across cores. We tested the algorithms on the Carnegie Mellon Latedays cluster, varying from 1 to 8 nodes.
                    </p>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <h3> What is a Suffix Array?</h3>
                    <p>
                        A suffix array is a data structure which stores the suffixes of a string in sorted order. Let <em>S</em> be a length <em>n</em> string. It stores an array which at entry <em>i</em> stores the starting index of the lexicographically <em>i</em>th smallest suffix (the suffix at index <em>i</em> is <em>S[i ... n - 1]</em>). The suffix array is related to the suffix tree data structure, but uses a smaller memory footprint (approximately 5 times less) and has the benefit of cache locality.
                    </p>
                    <p>
                        Suffix arrays are used in numerous compression algorithms, and speed up many string operations, like substring search. Hence increased performance from either multithreaded, distributed, or CUDA accelerated programs greatly impacts the ability to work and operate efficiently on large data sets.
                    </p>
                    <p>
                        There are two common algorithms for suffix array construction. The DC3 algorithm contracts the problem and solves a subproblem of size 2/3, and uses to solution to create the suffix array in linear time. It works by carefully selecting a subset of suffixes and sorts the suffixes and additional data. We implemented a distributed version of this algorithm.
                    </p>
                    <p>
                        The other algorithm, prefix doubling, works by sorting fixed sized suffixes in rounds, doubling in size each round. It first sorts by 1 character, then 2 characters, then 4 characters, and so on. It often uses radix sorting.
                    </p>
                    <p>
                        The most expensive part of the algorithm is the sort. The algorithm requires some type of sort to arrange the suffixes. Suffixes can be linear in the size of the array, so the type of sort depends on the algorithm, i.e, the number of characters per suffix the algorithm uses. An algorithm which uses too much of the suffix may end of using too much memory, so there needs to be between balance between memory usage and speed. Once we begin to parallelize this, the algorithms will require significant amounts of communication between nodes, so this needs to be taken into account.
                    </p>
                    <p>
                        These are the most common <a href="#applications" class="page-scroll"> applications. </a>
                    </p>
                </div>
                <div class="container">
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 text-center">
                        <h2 class="section-heading"><b> pDC3 </b> (Parallel Difference Cover modulo 3)</h2>
                        <hr class="primary">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <h3 class="primary"> Algorithm </h3>
                    <p>
                        The sequential Difference Cover modulo 3 (DC3) algorithm for constructing suffix arrays is as follows:
                        <ul>
                            <li> For each index in the string, get the triple of three consecutive characters starting at that index. </li>
                            <li> Sort these triples. If there are not unique, then, recursively solve for the suffix array of these triples of the corresponding indices <em>i</em> where <em>i mod 3</em> is not zero. This is a subproblem of size <em> 2/3</em> of the original input. </li>
                            <li> Using the result of the recursive call to construct 3 arrays containing information about the positions of suffixes for indices which are <em> 0,1,2 mod 3</em>. </li>
                            <li> Combine and sort these three arrays using a carefully chosen comparator.</li>
                        </ul>
                    </p>
                    <p>
                        For large datafiles on the order of several gigabytes, it is not memory efficient to attempt to compute the suffix array on a single machine. We thus
                        aim to construct the suffix array in parallel across several machines. The bulk of the work consists several rounds of sorting, which can be parallelized to improve efficiency even when the datafiles are not huge. In addition, the algorithm iterates over arrays several times, which is obviously parallelizable.
                    </p>
                    <h3> Parallelization </h3>
                    <p>
                        We wrote our parallel implementation of the DC3 algorithm in C++ and used MPI to communicate across nodes on the Latedays cluster.
                        To parallelize the algorithm, we spawned several processes on each node and gave roughly equal contiguous chunks of the input to each process.
                        Our algorithm is similar to that of the sequential DC3 algorithm. However, merging is difficult to parallelize, so we choose to sort everything instead of
                        merging.
                    </p>
                    <p>
                        We make a few changes to the sequential DC3 algorithm.
                        Since merging is difficult to parallelize, we choose to
                        sort everything instead of merging. In addition,
                        instead of actually recursively calling our algorithm,
                        we send all of the data to one node and run a
                        sequential implementation (the SA-IS algorithm implemented by Yuta Mori). This was originally just for testing
                        purposes; we were planning on expanding our
                        implementation to recursively call itself. However,
                        after timing our algorithm, it became clear that the
                        runtime would be fairly poor even if the algorithm did recursively call itself. (This is discussed further in the Results section.) We thus chose not to
                        complete the recursive implementation.
                    </p>
                    <p>
                        Much of the runtime lies in sorting and necessary communication. We were able to reduce the communication costs somewhat by representing our elements in a compact way, and we sped up sorting by writing fast comparison functions. (This is not entirely trivial because at one point in our algorithm we have four-tuples and five-tuples that need to be sorted with a non-lexicographic comparison function.)
                    </p>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 text-center">
                        <h2 class="section-heading"><b> pCSS </b> (Parallel Cascading Suffix Sort)</h2>
                        <hr class="primary">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <h3> Algorithm and Motivation </h3>
                    <p>
                        We decided to develop a new algorithm which is inspired from pDC3, prefix doubling, and other suffix sorting algorithms. We wanted to reduce the amount of inter-node MPI communication, as this was taking the bulk of the execution time for pDC3. pDC3 also had a high per-character memory overhead.
                    </p>
                    <p>
                        <ul>
                            <li> Create and array of 8-length contiguous substrings (samples) for each position in the string.</li>
                            <li> Sort the array of samples.</li>
                            <li> Now, all suffixes are sorted by the first 8-letters across the nodes. Find contiguous sequences of equal samples in each node, and sort them using a simple sequential sort. </li>
                        </ul>
                    </p>
                    <h3>Parallelization </h3>
                    <p>
                        We first assign contiguous chunks of the string to each processing node. Each node calculates its 8-length samples for each index in the string, for its individual part. We choose 8 simply since 8 characters can fit into a 64-byte long long datatype, and allows the string to have much higher entropy during the per-node sorting phase. These samples are sorted using sample sort. Once this is complete, we have a representation of the suffixes such that they are sorted by the first 8 characters.
                    </p>
                    <p>
                        However, substrings with the equal samples are possibly unsorted. These lie contiguously. Hence, on each node, we search for contiguous sequences of equal samples. For each sequence, we sort the sequences of equal samples using a naive technique which just compares the suffixes at both positions. Hence the worst case runtime is large, however the average case runtime is fairly small. It is possible to improve this using advanced techniques, but we did not pursue these.
                    </p>
                    <p>
                        Once we have sorted the sequences per node, we have to sort the contiguous sequences which lie at the boundary of nodes. This requires adjacent node communication. In the average case, this communication will be very small, or even nonexistent. After this, we have a fully sorted suffix array.
                    </p>
                    <h3> Optimizations and Performance</h3>
                    <p>
                        We use 64-byte integers to store the samples. This allows for easy sorting, as sorting is simply an integer sort and not a string sort. This makes it possible to replace sample sort which a possibly faster integer specific sort. All in all, this algorithm requires only 1 call to a multi-node sort. After this, the communication is minimal. So this substantially improves upon the communication complexity of pDC3. In addition, the sort in pCSS makes lightweight integer comparisions, where the comparators in the different sorts of pDC3 require much heavier comparators.
                    </p>
                    <p>
                        We only spawn 1 MPI process per node. To achieve inter-node parallelism, we use OpenMP. This allows us to spawn multiple threads per node and parallelize the local sorting across the individual portion of the string on the node. In addition, this allows the samplesort to take advantage of a multithread per-core sort. In samplesort, each processing element needs to locally sort its chunk of elements. As the granularity of processing elements are now nodes, we do this using OpenMP threads to parallelize the sort. GCC has parallel extensions through OpenMP, so we simply have to compile with parallel flags.
                    </p>
                    <p>
                        To find contiguous sequences of equal samples, we simply loop through the array. We utilize the multiple threads per node to split this into parallel searches. At the end, we have to look for contiguous sequences across threads, and then across nodes.
                    </p>
                    <p>
                        However, this method has its drawbacks. In the current implementation, of the string contains a large number of very long repeats, then the local sort on that sequence will be slow, since we are search through the entire suffix. However we argue that it is unlikely for this to happen over most strings, so the cost of this operation will be low. We can also tune the length of samples to improve the performance of low entropy strings. Importantly, this algorithm in its current implementation requires the entire string be accessible to each node. For our implementation, we simply loaded the string into each node. However we can reduce this cost to node communication. Each node needs access to the whole string during the local sorting phase, but this can be probably replaced with communicating with the appropriate node, instead of storing the whole string. The amount of computation during the local sorting is small, so we don't expect using node-to-node communication to substantially increase the cost.
                    </p>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 text-center">
                        <h2 class="section-heading">Sorting</h2>
                        <hr class="primary">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <p>
                        Sorting data across several nodes is a crucial part of both pDC3 and pCSS. To accomplish this, we
                        wrote an implementation of <em>samplesort</em> in MPI and C++. Samplesort takes as input an array and a comparison function. The end result is that if the data from each
                        processor is concatenated in order of processor ID, the
                        concatenation is sorted.  For <i>p</i> processors, the
                        algorithm is as follows:
                        <ul>
                            <li>Sample <i>p</i>-1 "splitting" points from the input data</li>
                            <ul>
                                <li>Each processor samples some points from its local data.</li>
                                <li>Gather all these local samples at one processor and pick the splitters based on these local samples. Sort these splitters.</li>
                                <li>Broadcast the splitters to all the processors</li>
                            </ul>
                            <li>Each processor partitions its local data into <i>p</i> buckets based on the splitters. Each bucket holds data that falls within an interval where the interval's endpoints are adjacent splitters.
                            The buckets have the property that each element in bucket <i>i</i> is "less than" any element bucket <i>j</i> (where "less than" is defined by the input comparison function) if <i>i</i> is less than <i>j</i>.</li>
                            <li>Give all the elements of bucket <i>i</i> to processor <i>i</i> and sort each bucket.</li>
                        </ul>
                    </p>
                    <p>
                        There was not much to optimize here. Most of the runtime
                        comes from communication and two rounds of local
                        sorting. We could not find any way to avoid this
                        communication and sorting altogether. One of the rounds
                        of sorting can be replaced by a multiway merge, which
                        is asymptotically faster. However, our implementation
                        of merging turned out to be slower than the original
                        sort, so we did not use this in our final samplesort
                        implementation.
                    </p>
                    <p>
                        For the granularity of calling samplesort across nodes in pCSS, as opposed to per process, we parallelized the local sorting by using <a href="https://gcc.gnu.org/onlinedocs/libstdc++/manual/parallel_mode.html"> GCC's parallel extensions </a>. This is a parallel extension to GCC's algorithms using the OpenMP framework. This allowed full utilization of each node for local sorting.
                    </p>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 text-center">
                        <h2 class="section-heading">Results</h2>
                        <hr class="primary">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <h3> Measuring Results </h3>
                    <p>
                        We measured performance by find the wall-clock time to construct the suffix array. These times do not include the time it takes convert the read input textfile into a char array and write the output suffix array. This also does not include the time for provisioning a cluster.
                    </p>
                </div>
                <div class="row">
                    <h3> Experimental Setup </h3>
                    <p>
                        For our inputs, we generated files of random mixed-case English letters. We did this for sizes 1MB, 5MB, 10MB, 20MB, 50MB, 100MB, 250MB, 500MB, 750MB, and 1GB. In addition, we use real world datasets from <a href="http://www.cs.cmu.edu/~pbbs/benchmarks/suffixArray.html">Guy Blelloch's PBBS</a> (Problem Based Benckmark Suite), namely etext, chr22, wikisamp, and trigrams.
                    </p>
                </div>
                <div class="row">
                    <h3> Baseline </h3>
                    <p>
                        To compare the performance our of parallel algorithms, we use an <a href="https://sites.google.com/site/yuta256/sais"> Yuta Mori's implementation </a> of the SA-IS algorithm by <a href="http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4976463"> Nong, Zhang & Chan (2009) </a>. This uses the method of induced sorting to construct suffix arrays. This implementation is commonly used as a baseline in other suffix array papers and it one of the fastest (if not the fastest) single-threaded implementation. It has both linear construction time and optimal memory usage.
                    </p>
                </div>
                <div class="row">
                    <div class="col-lg-6 center">
                        <table class = "table table-bordered">
                            <caption>SA-IS Baseline Runtimes</caption>
                            <thead>
                                <tr>
                                    <th>Dataset</th>
                                    <th>Runtime (s)</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr><td> trigrams </td><td> 0.0001 </td> </tr>
                                <tr><td> wikisamp  </td><td>  1.54</td> </tr>
                                <tr><td> chr22.dna  </td><td> 1.44</td> </tr>
                                <tr><td> etext  </td><td> 5.46</td> </tr>
                                <tr><td> random 1MB </td><td> 0.16</td> </tr>
                                <tr><td> random 5MB </td><td> 0.83</td> </tr>
                                <tr><td> random 10MB </td><td>1.52</td> </tr>
                                <tr><td> random 20MB </td><td>3.06</td> </tr>
                                <tr><td> random 50MB </td><td>7.89</td> </tr>
                                <tr><td> random 100MB </td><td>16.00</td> </tr>
                                <tr><td> random 250MB </td><td>40.69</td> </tr>
                                <tr><td> random 500MB </td><td>81.73</td> </tr>
                                <tr><td> random 750MB </td><td> 130.06</td> </tr>
                                <tr><td> random 1GB </td><td> 205.00</td> </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
                <div class="row">
                    <h3> Data </h3>
                </div>
                <div class="row">
                    <div class="col-lg-10 center">
                        <table class = "table table-bordered">
                            <caption>pCSS Runtimes</caption>
                            <thead>
                                <tr>
                                    <th>Dataset</th>
                                    <th>1 Node Runtime (s)</th>
                                    <th>2 Node Runtime (s)</th>
                                    <th>4 Node Runtime (s)</th>
                                    <th>8 Node Runtime (s)</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr><td> trigrams</td><td>0.04256</td><td>0.069251 </td><td>0.067058</td><td>0.06885</td> </tr>
                                <tr><td>wikisamp</td><td>1.110653</td><td>1.353469</td><td>0.899169</td><td>0.599915</td> </tr>
                                <tr><td>chr22.dna</td><td>1.099506 </td><td>1.311307</td><td>0.858363</td><td>0.574447</td> </tr>
                                <tr><td>etext</td><td>2.843792</td><td>4.105355</td><td>2.768228</td><td>1.626782</td> </tr>
                                <tr><td>random 1MB</td><td>0.164474</td><td>0.188504</td><td>0.168423</td><td>0.128414</td> </tr>
                                <tr><td>random 5MB</td><td>0.730067</td><td>0.79204</td><td>0.568226</td><td>0.374353</td> </tr>
                                <tr><td>random 10MB</td><td>1.323709</td><td>1.478898</td><td>1.026515</td><td>0.665979</td> </tr>
                                <tr><td>random 20MB</td><td>2.064725</td><td>2.944016</td><td>1.951967</td><td>1.219765</td> </tr>
                                <tr><td>random 50MB</td><td>4.244969</td><td>6.467543</td><td>4.775463</td><td>2.739247</td> </tr>
                                <tr><td>random 100MB</td><td>7.209381</td><td>11.327291</td><td>8.386905</td><td>5.078551</td></tr>
                                <tr><td>random 250MB</td><td>19.277768</td><td>28.263648</td><td>19.477082</td><td>11.092358</td> </tr>
                                <tr><td>random 500MB</td><td>Out of memory</td><td>  54.081576</td><td>40.688515</td><td>   29.501891</td> </tr>
                                <tr><td>random 750MB</td><td>Out of memory</td><td> Out of memory</td><td>59.407972</td><td> 38.01542</td> </tr>
                                <tr><td>random 1GB</td><td> Out of memory</td><td>Out of memory</td><td>79.404072</td><td>51.243268</td> </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <h3> Graphs </h3>
                </div>
                <div class="row">
                    <div class="col-lg-12 text-center">
                        <img src="./img/pcss_speedup.jpg" class="img-responsive" style="margin: 10px 10px 10px 10px;">
                    </div>
                </div>
                <div class="row">

                    <div class="col-lg-12 text-center">
                        <img src="./img/pcss_mpi.jpg" class="img-responsive" style="margin: 10px 10px 10px 10px;">
                    </div>
                </div>
                <div class="row">
                    <div class="col-lg-12 text-center">
                        <img src="./img/pdc3_speedup.jpg" class="img-responsive" style="margin: 10px 10px 10px 10px;">
                    </div>
                </div>
                The above graph shows the speedup of pDC3 running on four nodes
                compared to SA-IS. Notice that pDC3 is actually slower than
                SA-IS even though SA-IS is completely sequential. The relative
                performance of pDC3 improves somewhat as the problem sizes become large.
                <div class="row">
                    <div class="col-lg-12 text-center">
                        <img src="./img/pdc3_mpi.jpg" class="img-responsive" style="margin: 10px 10px 10px 10px;">
                    </div>
                </div>
                Here we break down the runtime of pDC3. The blue bars represent
                the runtime taken up by MPI data transfers. The red bars
                represent the runtime taken up by local calls to STL sort in
                the implementation of samplesort. The grey bars make up
                everything else, including the call SA-IS. If the call to SA-IS
                were excluded from the grey bars, then we would see that the
                MPI and sort calls take up a vast majority of the execution time.
                <div class="row">
                    <div class="col-lg-12 text-center">
                        <img src="./img/pdc3_recur.jpg" class="img-responsive" style="margin: 10px 10px 10px 10px;">
                    </div>
                </div>
                In the above graph, the blue bar represents the proportion of
                the run time taken up by the call to sequential SA-IS. The
                timing includes the time to send all the data to one node. Note
                that the recursive call actually does not take up a huge amount
                of the run time until input sizes are very large.
                <div class="row">
                    <h3> Performance Analysis </h3>
                </div>
                <div class="row">
                    <h4> pDC3 </h4>
                    <p>
                        We found that almost all of the run time of pDC3 comes
                        from MPI communication, calls to STL sort in the
                        implementation of samplesort, and calling SA-IS.
                    </p>
                    <p>
                        The algorithm is data-transfer-bound and memory-bound.
                        This is not hard to guess based on the fact that pDC3
                        consists mostly of writing data and sending it to other
                        processors with very little arithmetic involved. We
                        verified this guess by reducing the size of the
                        datatypes used and observing that the MPI communication
                        times and sorting times decreased dramatically.
                    </p>
                    <p>
                        It is difficult to optimize MPI communication and local
                        sorting, but what about the call to SA-IS? At first,
                        this seems like this is an obvious bottleneck to the
                        performance of pDC3 since we funnel all the data to a
                        single node and run a single-threaded algorithm.
                        Indeed, our original plan was to call pDC3 recursively
                        instead of calling SA-IS.
                    </p>
                    <p>
                        However, our results suggest that we would not gain any
                        performance by doing so until we reach inputs of over 750MB
                        in size. Experimentally, our algorithm seems to scale
                        roughly linearly with the problem size. If the size of
                        initial input is <i>n</i>, the sum of the problem sizes
                        of the recursive calls is <i>3n</i>. So if the
                        additional runtime at each recursive call is <i>cn</i>,
                        we expect the total runtime to be roughly <i>3cn</i>.
                        But actually, the actual runtime would be even worse
                        because the recursive call runs on larger datatypes
                        (since triplets of characters don't fit in a C char),
                        which is terrible for data transferring and memory
                        access. The conclusion is that our algorithm probably
                        would not gain any performance from removing the SA-IS
                        call until the amount of time taken up by the recursive
                        call is significantly more than twice the amount of
                        time taken up by everything else. In our experiments
                        running on four nodes, this doesn't occur until the
                        input size is on the order of a gigabyte.
                    </p>
                    <p>
                        Considering that our implementation is already much slower
                        than SA-IS is, we decided that this was not a worthy
                        avenue to pursue further.
                    </p>
                </div>
                <div class="row">
                    <h3> Machine Choice </h3>
                    <p>
                        Distributed suffix array construction is inherently going to
                        involve a lot of communication and memory access since each
                        node holds a large array and needs information from other
                        nodes in order to communicate suffixes. As such, either of
                        our algorithms would be better suited for a cluster with extremely
                        large memory and data transfer bandwidth.
                    </p>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 text-center">
                        <h2 class="section-heading">References</h2>
                        <hr class="primary">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <p>
                        An excellent source which provides background and a complete taxonomy of the types of suffix array construction algorithms (SACAs) and the varying implementations over the past 30 years is the following paper by Puglisi et. al: <a href="http://www.cas.mcmaster.ca/~bill/best/algorithms/07Taxonomy.pdf"> Taxonomy of Suffix Array Construction</a>.
                    </p>
                    <p>
                        The papers were useful in learning about CPU based suffix array construction:
                        <ul>
                            <li> <a href="http://arxiv.org/abs/1302.5851">Parallel Suffix Array Construction by Accelerated Sampling </a></li>
                            <li> <a href="http://arxiv.org/pdf/1307.1417v1.pdf">An Elegant Algorithm for the Construction of Suffix Arrays </a></li>
                            <li> <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7152610&tag=1"> Parallel DC3 Algorithm for Suffix Array Construction on Many-Core Accelerators </a></li>
                            <li> <a href="https://pdfs.semanticscholar.org/6eeb/4c131cb4039821208e7cb756395810aa9a0a.pdf"> Parallel Lightweight Wavelet Tree, Suffix Array and FM-Index Construction </a></li>
                        </ul>
                    </p>
                    <p>
                        These were the papers were referenced for distributed suffix array construction:
                        <ul>
                            <li> <a href="http://www.sciencedirect.com/science/article/pii/S0167819107000816"> Scalable parallel suffix array construction </a> </li>
                            <li> <a href="http://delivery.acm.org/10.1145/2810000/2807609/a16-flick.pdf?ip=128.237.73.121&id=2807609&acc=ACTIVE%20SERVICE&key=A792924B58C015C1%2E5A12BE0369099858%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=747335659&CFTOKEN=47718763&__acm__=1460868043_d6df6e9218c458c4b26bbf6fd43656f0"> Parallel Distributed Memory Construction of Suffix and Longest Common Prefix Arrays </a></li>
                        </ul>
                    </p>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <h3> Work Distribution</h3>
                    <p> Equal work was done by both members of the group. </p>
                </div>
            </div>
        </section>
        <aside class="bg-dark">
        </aside>
        <section id="checkpoint">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 text-center">
                        <h2 class="section-heading">Project Checkpoint</h2>
                        <hr class="primary">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <h3>
                    <a id="dschedule" class="anchor" href="#dschedule" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Detailed Schedule</h3>
                    <p>
                        <ul>
                            <li> <b> [4/18 - 4/21:] </b> Read through Flick and Aluru paper on distributed suffix arrays. Read Kulla and Sanders paper. Design implementation for Latedays cluster. Research and learn about MPI. <br>
                                <b> Sunny </b>: Begin design and implementation of per node suffix array construction. Write high level code with a modular API which can easily be worked on in parallel. <br>
                                <b> Tom </b>: Get MPI working on latedays. Develop a test application splitting work across the lateday nodes and test multi-machine functionality. <br><br>
                            </li>
                            <li> <b> [4/21 - 4/24:] </b> Study HARD for EXAM 2. <br>
                                <b> Tom </b>: Research efficient distributed sorting algorithms. <br>
                                <b> Sunny </b>: Starting implementing modules for pDC3. <br>
                                <ul>
                                    <li> K-mer sorting. </li>
                                    <li> Re-bucketing. </li>
                                    <li> Reorder to string order. </li>
                                    <li> Shifting. </li>
                                    <li> Tuple sorting. </li>
                                    <li> Data distribution. </li>
                                    <li> Bucket sorting. </li>
                                    <li> Update ISA. </li>
                                </ul>
                            </li>
                            <li> <b> [4/25 - 4/28:] </b> Continuing implementation. <br>
                                <b> Sunny </b>: Implementation of modules. <br>
                                <b> Tom </b>: Implementation of sorting module + others. <br><br>
                            </li>
                            <li> <b> [4/29 - 5/2:] </b> Finishing and testing implementation. <br>
                                <b> Sunny </b>: Finish implementation. Start testing on basic data sets. <br>
                                <b> Tom </b>: Find large 10-30GB data sets. <br><br>
                            </li>
                            <li> <b> [5/3 - 5/5:] </b> Debugging and optimization. <br>
                                <b> Sunny </b>: Optimize per machine performance. Try offloading onto Xeon Phi. <br>
                                <b> Tom </b>: Optimize communication and data distribution. <br><br>
                            </li>
                            <li> <b> [5/6 - 5/9:] </b> Prepare for presentation. Develop the demo. <br>
                                <b> Sunny </b>: Prepare slides and graphs and tables. <br>
                                <b> Tom </b>: Create a demo showing the construction on Latedays. <br>
                            </li>
                        </ul>
                    </p>
                    <h3>
                    <a id="workcompleted" class="anchor" href="#workcompleted" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Stretch goals</h3>
                    <p>
                        <ul>
                            <li> Demo of sample string search or match queries. </li>
                            <li> Implement Prefix Doubling (more complex algorithm). </li>
                        </ul>
                    </p>
                    <h3>
                    <a id="workcompleted" class="anchor" href="#workcompleted" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Work Completed</h3>
                    <p>
                        We researched numerous parallel approaches to suffix array constructions, both on the CPU, and GPU. We found an excellent source which provides background and a complete taxonomy of the types of suffix array construction algorithms (SACAs) and the varying implementations over the past 30 years. This paper is Puglisi et. al's <a href="http://www.cas.mcmaster.ca/~bill/best/algorithms/07Taxonomy.pdf"> Taxonomy of Suffix Array Construction</a>.
                    </p>
                    <p>
                        We read the following papers describing suffix array construction on the CPU:
                        <ul>
                            <li> <a href="http://arxiv.org/abs/1302.5851">Parallel Suffix Array Construction by Accelerated Sampling </a></li>
                            <li> <a href="http://arxiv.org/pdf/1307.1417v1.pdf">An Elegant Algorithm for the Construction of Suffix Arrays </a></li>
                            <li> <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7152610&tag=1"> Parallel DC3 Algorithm for Suffix Array Construction on Many-Core Accelerators </a></li>
                            <li> <a href="https://pdfs.semanticscholar.org/6eeb/4c131cb4039821208e7cb756395810aa9a0a.pdf"> Parallel Lightweight Wavelet Tree, Suffix Array and FM-Index Construction </a></li>
                        </ul>
                        In addition, the following papers were for construction on the GPU:
                        <ul>
                            <li> <a href="http://dl.acm.org/citation.cfm?id=2442536">Parallel suffix array and least common prefix for the GPU </a> </li>
                            <li> <a href="http://link.springer.com/chapter/10.1007/978-3-662-48096-0_44">Fast Parallel Suffix Array on the GPU </a> </li>
                            <li> <a href="http://download.springer.com/static/pdf/62/chp%253A10.1007%252F978-3-642-34109-0_40.pdf?originUrl=http%3A%2F%2Flink.springer.com%2Fchapter%2F10.1007%2F978-3-642-34109-0_40&token2=exp=1460874530~acl=%2Fstatic%2Fpdf%2F62%2Fchp%25253A10.1007%25252F978-3-642-34109-0_40.pdf%3ForiginUrl%3Dhttp%253A%252F%252Flink.springer.com%252Fchapter%252F10.1007%252F978-3-642-34109-0_40*~hmac=bd75e4bf5dde89b600c11b5dadb0c223dbced01ab18013c5cceaf51e46210c06">Parallel Suffix Array Construction for Shared Memory Architectures </a> </li>
                        </ul>
                        And finally, these were the papers on distributed suffix array construction:
                        <ul>
                            <li> <a href="http://www.sciencedirect.com/science/article/pii/S0167819107000816"> Scalable parallel suffix array construction. </a> </li>
                            <li> <a href="http://delivery.acm.org/10.1145/2810000/2807609/a16-flick.pdf?ip=128.237.73.121&id=2807609&acc=ACTIVE%20SERVICE&key=A792924B58C015C1%2E5A12BE0369099858%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=747335659&CFTOKEN=47718763&__acm__=1460868043_d6df6e9218c458c4b26bbf6fd43656f0"> Parallel Distributed Memory Construction of Suffix and Longest Common Prefix Arrays </a></li>
                        </ul>
                    </p>
                    <p>
                        We also downloaded and tried to run Guy Blelloch's <a href="http://www.cs.cmu.edu/~pbbs/benchmarks/suffixArray.html"> PBBS (Problem Based Benchmark Suite) for suffix arrays </a>, in which there are implementations of the CPU based parallel DC3 and Prefix doubling algorithms. The benchmark code segfaulted when run in parallel on almost all of the larger (>10MB) datasets. We were not able to find the errors and fix the benchmark.
                    </p>
                    <p>
                        Due to the numerous available and likely highly-optimized implementations of parallel suffix array construction on the CPU, and recent literature on GPU based construction, and the complications in running Guy's benchmark suite, we decided that simply doing CPU and GPU based suffix array construction would not benefit our learning the most. It would also be difficult to implement faster versions using the same algorithm.
                    </p>
                    <p>
                        We instead switched our focus to distributed suffix array construction algorithms. Most of the papers we read were only able to run on data sets of at most 2GB, which can be small, if you are dealing with areas which generally used large datasets (genomics). We want to build a distributed suffix array construction which can handle datasets of 10-30GB while achieving high parallelism. We plan to utilize Latedays to test our algorithm.
                    </p>
                    <p>
                        The papers described in the distributed section show approaches to both parallel DC3 and parallel Prefix doubling. The algorithm for prefix doubling is fairly complex, and in the paper, the testbed was 1024-1600 cores. We believe that on a smaller system like Latedays, parallel DC3 will be the better option since it has less overhead. We plan on building our suffix array construction algorithm using ideas from the Kulla and Sanders paper. As a stretch goal, we will try to implement the other algorithm as well to provide a comparison.
                    </p>
                    <h3>
                    <a id="updateddeliverables" class="anchor" href="#updateddeliverables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Updated Deliverables</h3>
                    <p>
                        What we expect to have:
                        <ul>
                            <li> Working implementation which can handle large datasets and achieve comparable speedups. </li>
                            <li> Demo of algorithm on data set. </li>
                        </ul>
                    </p>
                    <p>
                        Stretch goals:
                        <ul>
                            <li> Implement LCP array along with suffix array. </li>
                            <li> Implement prefix doubling. </li>
                        </ul>
                    </p>
                    <h3>
                    <a id="concerns" class="anchor" href="#concerns" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Concerns</h3>
                    <p>
                        We will want to test our implementation on datasets that are several gigabytes in size. We don't have enough AFS space to hold these datasets, though.
                    </p>
                </div>
            </div>
        </section>
        <aside class="bg-dark">
        </aside>
        <section id="proposal">
            <div class="container">
                <div class="row">
                    <div class="col-lg-12 text-center">
                        <h2 class="section-heading">Project Proposal</h2>
                        <hr class="primary">
                    </div>
                </div>
            </div>
            <div class="container">
                <div class="row">
                    <h3>
                    <a id="summary" class="anchor" href="#summary" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Summary</h3>
                    <p>We are going to implement parallel suffix array construction on the latedays cluster. We plan on implementing both a multithreaded CPU algorithm and a CUDA GPU-based algorithm, and compare our performance to existing benchmarks.</p>
                </div>
                <div class="row">
                    <h3>
                    <a id="background" class="anchor" href="#background" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Background</h3>
                    <p>A suffix array is a data structure that stores the suffixes of a word in sorted order. It stores an array which at entry i stores the starting index of the lexicographically ith smallest suffix. The suffix array is related to the suffix tree data structure, but uses a smaller memory footprint (5 times less) and has the benefit of cache locality.
                        <br><br>
                        Suffix arrays are used in numerous compression algorithms, and speed up many string operations, like substring search. Hence increased performance from either multithreaded or CUDA accelerated programs greatly impacts the ability to work and operate efficiently on large data sets.
                        <br><br>
                        There are two common algorithms for suffix array construction. The DC3 algorithm solves a subproblem of size 2/3, and uses to solution to create the suffix array in linear time. It works by carefully selecting a subset of suffixes and calls radix sort.
                        <br><br>
                        The Prefix doubling algorithm works by sorting suffixes by first 1 character, then by first 2 characters, then by first 4 characters, then by first 8 characters, and so on. It often uses radix sorting.
                        <br><br>
                        The papers listed below in Resources describe variants and improvements to the above algorithms.
                    </p>
                </div>
                <div class="row">
                    <h3>
                    <a id="challenges" class="anchor" href="#challenges" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Challenges</h3>
                    <p>
                        For the prefix-doubling algorithm, each round of sorting depends on the previous round of sorting. Sorting doesn't have a great amount of locality and has considerable divergence. Also, prefixes are put in buckets as sorting occurs, but the distrbution of data within the buckets is data-dependent and will likely be non-uniform. This leads to load imbalance.
                        <br><br>
                        For the DC3 algorithm, the recursive structure creates many dependencies. In addition, it uses some comparison-based sorting and merging, which can be expensive for strings.
                        <br><br>
                        We must figure out which algorithm is fastest and find ways to mitigate its flaws.
                        <br><br>
                        Lastly, GPUs have limited memory, so when we divide up work, we must find a reasonable way to portion the large inputs into chunks such that we minimize communication requirements and maximize locality.
                    </p>
                </div>
                <div class="row">
                    <h3>
                    <a id="resources" class="anchor" href="#resources" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Resources</h3>
                    <p>
                        Paper references:
                        <br>
                        GPU based construction:
                        <ul>
                            <li> <a href="http://dl.acm.org/citation.cfm?id=2442536">Parallel suffix array and least common prefix for the GPU </a> </li>
                            <li> <a href="http://link.springer.com/chapter/10.1007/978-3-662-48096-0_44">Fast Parallel Suffix Array on the GPU </a> </li>
                            <li> <a href="http://dl.acm.org/citation.cfm?id=2442536"> Parallel suffix array and least common prefix for the GPU </a> </li>
                            <li> <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7152610&tag=1"> Parallel DC3 Algorithm for Suffix Array Construction on Many-Core Accelerators </a></li>
                        </ul>
                        Parallel construction:
                        <ul>
                            <li> <a href="http://arxiv.org/abs/1302.5851">Parallel Suffix Array Construction by Accelerated Sampling </a></li>
                            <li> <a href="http://arxiv.org/pdf/1307.1417v1.pdf">An Elegant Algorithm for the Construction of Suffix Arrays </a></li>
                        </ul>
                        Starter code, test inputs, baseline benchmarks:
                        <a href="http://www.cs.cmu.edu/~pbbs/benchmarks.html"> Problem Based Benchmark Suite (PBBS) </a>
                        <br><br>
                        We will have to scan papers and examine source code to determine if there is a suitable benchmark for GPU-based algorithms.
                        <br><br>
                        The benchmark parallel implementation is in Cilk. We plan on using this framework, and will investigate other possible parallel frameworks, like OpenMP or simply pthreads.
                    </p>
                </div>
                <div class="row">
                    <h3>
                    <a id="goals" class="anchor" href="#goals" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Goals and Deliverables</h3>
                    <p>
                        Plan to achieve:
                        <ul>
                            <li> Write an implementation for the CPU that is about as fast as the PBBS implementation. This should be achievable if we can understand the algorithm in the PBBS implementation. It's not clear whether or not we can reasonably get significant speedup. </li>
                            <li> Write an implementation for the GPU that is significantly faster than the PBBS implementation. Speedup is possible due to the theoretically high instruction throughput of GPUs compared to CPUs. </li>
                        </ul>
                        Hope to achieve:
                        <ul>
                            <li> Write an implementation for the CPU that is significantly faster than the PBBS implementation. </li>
                            <li> Extend our implementation to a distributed multi-node efficient implementation which scales reasonably well. </li>
                        </ul>
                        Deliverables:
                        <ul>
                            <li> We will show speedup graphs at the parallelism competition. </li>
                            <li> We will aim to have a real-time demo of our algorithm working and its performance improvements compared to the baseline. </li>
                        </ul>
                    </p>
                </div>
                <div class="row">
                    <h3>
                    <a id="platform" class="anchor" href="#platform" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Platform</h3>
                    <p>The latedays cluster has multiple nodes and GPUs, so we can test both a parallel distributed version and a GPU version.</p>
                    <h3>
                    <a id="schedule" class="anchor" href="#schedule" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Schedule</h3>
                    <p>
                        <ul>
                            <li> [4/1 - 4/8:] Read papers which describe parallel suffix array algorithms. Understand different algorithms and their behaviors, runtimes, etc. Determine if there is source code for their implementations. Test possible implementations on benchmark data. Understand benchmark implementations. Start developing our own implementations </li>
                            <li> [4/8 - 4/15:] Write a parallel implementation for CPU, comparing with benchmark.</li>
                            <li> [4/15 - 4/22:] Continue writing CPU implementation. Write parallel implementation for GPU. </li>
                            <li> [4/22 - 4/29:] Continue writing the suffix array implementation for GPU. </li>
                            <li> [4/29 - 5/6:] Crunch through the code and continue to optimize and test our implementations, using our 418 skills. Compile detailed runtime analysis over benchmark data sets. Profile implementations to squeeze out performance. </li>
                            <li> [5/6 - 5/9] Prepare for presentation. Develop the demo. </li>
                        </ul>
                    </p>
                </div>
            </div>
        </section>
        <aside class="bg-dark">
        </aside>
        <!--   <section class="no-padding" id="portfolio">
            <div class="container-fluid">
                <div class="row no-gutter">
                    <div class="col-lg-4 col-sm-6">
                        <a href="#" class="portfolio-box">
                            <img src="img/portfolio/1.jpg" class="img-responsive" alt="">
                            <div class="portfolio-box-caption">
                                <div class="portfolio-box-caption-content">
                                    <div class="project-category text-faded">
                                        Category
                                    </div>
                                    <div class="project-name">
                                        Project Name
                                    </div>
                                </div>
                            </div>
                        </a>
                    </div>
                    <div class="col-lg-4 col-sm-6">
                        <a href="#" class="portfolio-box">
                            <img src="img/portfolio/2.jpg" class="img-responsive" alt="">
                            <div class="portfolio-box-caption">
                                <div class="portfolio-box-caption-content">
                                    <div class="project-category text-faded">
                                        Category
                                    </div>
                                    <div class="project-name">
                                        Project Name
                                    </div>
                                </div>
                            </div>
                        </a>
                    </div>
                    <div class="col-lg-4 col-sm-6">
                        <a href="#" class="portfolio-box">
                            <img src="img/portfolio/3.jpg" class="img-responsive" alt="">
                            <div class="portfolio-box-caption">
                                <div class="portfolio-box-caption-content">
                                    <div class="project-category text-faded">
                                        Category
                                    </div>
                                    <div class="project-name">
                                        Project Name
                                    </div>
                                </div>
                            </div>
                        </a>
                    </div>
                    <div class="col-lg-4 col-sm-6">
                        <a href="#" class="portfolio-box">
                            <img src="img/portfolio/4.jpg" class="img-responsive" alt="">
                            <div class="portfolio-box-caption">
                                <div class="portfolio-box-caption-content">
                                    <div class="project-category text-faded">
                                        Category
                                    </div>
                                    <div class="project-name">
                                        Project Name
                                    </div>
                                </div>
                            </div>
                        </a>
                    </div>
                    <div class="col-lg-4 col-sm-6">
                        <a href="#" class="portfolio-box">
                            <img src="img/portfolio/5.jpg" class="img-responsive" alt="">
                            <div class="portfolio-box-caption">
                                <div class="portfolio-box-caption-content">
                                    <div class="project-category text-faded">
                                        Category
                                    </div>
                                    <div class="project-name">
                                        Project Name
                                    </div>
                                </div>
                            </div>
                        </a>
                    </div>
                    <div class="col-lg-4 col-sm-6">
                        <a href="#" class="portfolio-box">
                            <img src="img/portfolio/6.jpg" class="img-responsive" alt="">
                            <div class="portfolio-box-caption">
                                <div class="portfolio-box-caption-content">
                                    <div class="project-category text-faded">
                                        Category
                                    </div>
                                    <div class="project-name">
                                        Project Name
                                    </div>
                                </div>
                            </div>
                        </a>
                    </div>
                </div>
            </div>
        </section> -->
        <section id="contact">
            <div class="container">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2 text-center">
                        <h2 class="section-heading"> Authors and Contributors </h2>
                        <hr class="primary">
                        <p> Sunny Nahar (<a href="https://github.com/snnynhr" class="user-mention">@snnynhr</a>) and Tom Tseng (<a href="https://github.com/tomtseng" class="user-mention">@tomtseng</a>).</p>
                    </div>
                </div>
            </div>
        </section>
        <!-- jQuery -->
        <script src="js/jquery.js"></script>
        <!-- Bootstrap Core JavaScript -->
        <script src="js/bootstrap.min.js"></script>
        <!-- Plugin JavaScript -->
        <script src="js/jquery.easing.min.js"></script>
        <script src="js/jquery.fittext.js"></script>
        <script src="js/wow.min.js"></script>
        <!-- Custom Theme JavaScript -->
        <script src="js/creative.js"></script>
    </body>
</html>
