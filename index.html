<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Parallel Suffix Arrays by snnynhr</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Distributed Suffix Arrays on Heterogeneous Architectures</h1>
        <p></p>

        <p class="view"><a href="https://github.com/snnynhr/ParallelSuffixArrays">View the Project on GitHub <small>snnynhr/ParallelSuffixArrays</small></a></p>


        <ul>
          <li><a href="https://github.com/snnynhr/ParallelSuffixArrays/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/snnynhr/ParallelSuffixArrays/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/snnynhr/ParallelSuffixArrays">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>

<h2>
Project Checkpoint
</h2>

<h3>
<a id="dschedule" class="anchor" href="#dschedule" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Detailed Schedule</h3>
<p>
<ul>
  <li> [4/18 - 4/21:] Read through Flick and Aluru paper on distributed suffix arrays. Design implementation for Latedays cluster. Research and learn about MPI. <br>
  Sunny: Begin design and implementation of per node suffix array construction. Write high level code with a modular API which can easily be worked on in parallel. <br>
  Tom: Get MPI working on latedays. Develop a test application splitting work across the lateday nodes and test multi-machine functionality. <br><br>
  </li>
    <li> [4/21 - 4/24:] Study HARD for EXAM 2. <br>
    Tom: Research efficient distributed sorting algorithms. <br>
    Sunny: Starting implementing modules. <br>
    <ul>
    <li> K-mer sorting. </li>
    <li> Re-bucketing. </li>
    <li> Reorder to string order. </li>
    <li> Shifting. </li>
    <li> Tuple sorting. </li>
    <li> Data distribution. </li>
    <li> Bucket sorting. </li>
    <li> Update ISA. </li>
    <li> Prefix Doubling. </li>
    </ul>
    </li>
    <li> [4/25 - 4/28:] Continuing implementation. <br>
    Sunny: Implementation of modules. <br>
    Tom: Implementation of sorting module + others. <br><br>
    </li>
    <li> [4/29 - 5/2:] Finishing and testing implementation. <br>
    Sunny: Finish implementation. Start testing on basic data sets. <br>
    Tom: Find large 10-30GB data sets. <br><br>
    </li>
    <li> [5/3 - 5/5:] Debugging and optimization. <br>
    Sunny: Optimize per machine performance. Try offloading onto Xeon Phi. <br>
    Tom: Optimize communication and data distribution. <br><br>
    </li>
    <li> [5/6 - 5/9:] Prepare for presentation. Develop the demo. <br>
    Sunny: Prepare slides and graphs and tables. <br>
    Tom: Create a demo showing the construction on Latedays. <br>
    Strech goal: Demo of sample string search or match queries. <br>
    </li>
</ul>
</p>

<h3>
<a id="workcompleted" class="anchor" href="#workcompleted" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Work Completed</h3>
<p>
We researched numerous parallel approaches to suffix array constructions, both on the CPU, and GPU. We found an excellent source which provides background and a complete taxonomy of the types of suffix array construction algorithms (SACAs) and the varying implementations over the past 30 years. This paper is Puglisi et. al's <a href="http://www.cas.mcmaster.ca/~bill/best/algorithms/07Taxonomy.pdf"> Taxonomy of Suffix Array Construction</a>.
</p>
<p>
We read the following papers describing suffix array construction on the CPU:
<ul>

</ul>
In addition, the following papers were for construction on the GPU:
<ul>
</ul>
</p>
<p>
We also downloaded and tried to run Guy Blelloch's <a href="http://www.cs.cmu.edu/~pbbs/benchmarks/suffixArray.html"> PBBS (Problem Based Benchmark Suite) for suffix arrays </a>, in which there is an implementation of the parallel DC3 and Prefix doubling algorithms. The benchmark code segfaulted when run in parallel on almost all of the datasets. We were not able to find/fix benchmark.
</p>
<p>
Due to the numerous available and likely highly-optimized implementations of parallel suffix array construction on the CPU, and recent literature on GPU based construction, and the complications in running Guy's benchmark suite, we decided that simply doing CPU and GPU based suffix array construction would not benefit our learning the most. We instead switched our focus to distributed suffix array construction algorithms. Most of the papers we read were only able to run on data sets of at most 2GB. We want to build a distributed version which can handle datasets of 10-30GB while achieving high parallelism. We plan to utilize Latedays to test our algorithm.
</p>

<h3>
<a id="updateddeliverables" class="anchor" href="#updateddeliverables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Updated Deliverables</h3>
<p>
What we expect to have:
<ul>
<li> Working implementation which can handle large datasets and achieve comparable speedups. </li>
<li> Demo of algorithm on data set. </li>
</ul>
Stretch goals:
<ul>
<li> Implement LCP array along with suffix array. </li>
</ul>
</p>



<h2>
Project Proposal
</h2>
<h3>
<a id="summary" class="anchor" href="#summary" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Summary</h3>

<p>We are going to implement parallel suffix array construction on the latedays cluster. We plan on implementing both a multithreaded CPU algorithm and a CUDA GPU-based algorithm, and compare our performance to existing benchmarks.</p>

<h3>
<a id="background" class="anchor" href="#background" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Background</h3>

<p>A suffix array is a data structure that stores the suffixes of a word in sorted order. It stores an array which at entry i stores the starting index of the lexicographically ith smallest suffix. The suffix array is related to the suffix tree data structure, but uses a smaller memory footprint (5 times less) and has the benefit of cache locality.
<br><br>
Suffix arrays are used in numerous compression algorithms, and speed up many string operations, like substring search. Hence increased performance from either multithreaded or CUDA accelerated programs greatly impacts the ability to work and operate efficiently on large data sets.
<br><br>
There are two common algorithms for suffix array construction. The DC3 algorithm solves a subproblem of size 2/3, and uses to solution to create the suffix array in linear time. It works by carefully selecting a subset of suffixes and calls radix sort.
<br><br>
The Prefix doubling algorithm works by sorting suffixes by first 1 character, then by first 2 characters, then by first 4 characters, then by first 8 characters, and so on. It often uses radix sorting.
<br><br>
The papers listed below in Resources describe variants and improvements to the above algorithms.
</p>

<h3>
<a id="challenges" class="anchor" href="#challenges" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Challenges</h3>

<p>
For the prefix-doubling algorithm, each round of sorting depends on the previous round of sorting. Sorting doesn't have a great amount of locality and has considerable divergence. Also, prefixes are put in buckets as sorting occurs, but the distrbution of data within the buckets is data-dependent and will likely be non-uniform. This leads to load imbalance.
<br><br>
For the DC3 algorithm, the recursive structure creates many dependencies. In addition, it uses some comparison-based sorting and merging, which can be expensive for strings.
<br><br>
We must figure out which algorithm is fastest and find ways to mitigate its flaws.
<br><br>
Lastly, GPUs have limited memory, so when we divide up work, we must find a reasonable way to portion the large inputs into chunks such that we minimize communication requirements and maximize locality.
</p>

<h3>
<a id="resources" class="anchor" href="#resources" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Resources</h3>

<p>
Paper references:
<br>
GPU based construction:
<ul>
<li> <a href="http://dl.acm.org/citation.cfm?id=2442536">Parallel suffix array and least common prefix for the GPU </a> </li>
<li> <a href="http://link.springer.com/chapter/10.1007/978-3-662-48096-0_44">Fast Parallel Suffix Array on the GPU </a> </li>
<li> <a href="http://dl.acm.org/citation.cfm?id=2442536"> Parallel suffix array and least common prefix for the GPU </a> </li>
<li> <a href="http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7152610&tag=1"> Parallel DC3 Algorithm for Suffix Array Construction on Many-Core Accelerators </a></li>
</ul>

Parallel construction:
<ul>
<li> <a href="http://arxiv.org/abs/1302.5851">Parallel Suffix Array Construction by Accelerated Sampling </a></li>
<li> <a href="http://arxiv.org/pdf/1307.1417v1.pdf">An Elegant Algorithm for the Construction of Suffix Arrays </a></li>
</ul>
Starter code, test inputs, baseline benchmarks:
<a href="http://www.cs.cmu.edu/~pbbs/benchmarks.html"> Problem Based Benchmark Suite (PBBS) </a>
<br><br>
We will have to scan papers and examine source code to determine if there is a suitable benchmark for GPU-based algorithms.
<br><br>
The benchmark parallel implementation is in Cilk. We plan on using this framework, and will investigate other possible parallel frameworks, like OpenMP or simply pthreads.
</p>


<h3>
<a id="goals" class="anchor" href="#goals" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Goals and Deliverables</h3>

<p>
Plan to achieve:
<ul>
<li> Write an implementation for the CPU that is about as fast as the PBBS implementation. This should be achievable if we can understand the algorithm in the PBBS implementation. It's not clear whether or not we can reasonably get significant speedup. </li>
<li> Write an implementation for the GPU that is significantly faster than the PBBS implementation. Speedup is possible due to the theoretically high instruction throughput of GPUs compared to CPUs. </li>
</ul>

Hope to achieve:
<ul>
<li> Write an implementation for the CPU that is significantly faster than the PBBS implementation. </li>
<li> Extend our implementation to a distributed multi-node efficient implementation which scales reasonably well. </li>
</ul>

Deliverables:
<ul>
<li> We will show speedup graphs at the parallelism competition. </li>
<li> We will aim to have a real-time demo of our algorithm working and its performance improvements compared to the baseline. </li>
</ul>
</p>

<h3>
<a id="platform" class="anchor" href="#platform" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Platform</h3>

<p>The latedays cluster has multiple nodes and GPUs, so we can test both a parallel distributed version and a GPU version.</p>

<h3>
<a id="schedule" class="anchor" href="#schedule" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Schedule</h3>

<p>
<ul>
  <li> [4/1 - 4/8:] Read papers which describe parallel suffix array algorithms. Understand different algorithms and their behaviors, runtimes, etc. Determine if there is source code for their implementations. Test possible implementations on benchmark data. Understand benchmark implementations. Start developing our own implementations </li>
    <li> [4/8 - 4/15:] Write a parallel implementation for CPU, comparing with benchmark.</li>
    <li> [4/15 - 4/22:] Continue writing CPU implementation. Write parallel implementation for GPU. </li>
    <li> [4/22 - 4/29:] Continue writing the suffix array implementation for GPU. </li>
    <li> [4/29 - 5/6:] Crunch through the code and continue to optimize and test our implementations, using our 418 skills. Compile detailed runtime analysis over benchmark data sets. Profile implementations to squeeze out performance. </li>
    <li> [5/6 - 5/9] Prepare for presentation. Develop the demo. </li>
</ul>
</p>


<h3>
<a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors and Contributors</h3>

<p> Sunny Nahar (<a href="https://github.com/snnynhr" class="user-mention">@snnynhr</a>) and Tom Tseng (<a href="https://github.com/tomtseng" class="user-mention">@tomtseng</a>).</p>

      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/snnynhr">snnynhr</a> and <a href="https://github.com/tomtseng">tomtseng</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>

  </body>
</html>
